{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T09:40:46.704178956Z",
     "start_time": "2024-04-02T09:40:44.554498487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:1\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": "UNet3d(\n  (conv): DoubleConv(\n    (double_conv): Sequential(\n      (0): Conv3d(3, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n      (1): GroupNorm(8, 24, eps=1e-05, affine=True)\n      (2): ReLU(inplace=True)\n      (3): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n      (4): GroupNorm(8, 24, eps=1e-05, affine=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (enc1): Down(\n    (encoder): Sequential(\n      (0): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConv(\n        (double_conv): Sequential(\n          (0): Conv3d(24, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (1): GroupNorm(8, 48, eps=1e-05, affine=True)\n          (2): ReLU(inplace=True)\n          (3): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (4): GroupNorm(8, 48, eps=1e-05, affine=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (enc2): Down(\n    (encoder): Sequential(\n      (0): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConv(\n        (double_conv): Sequential(\n          (0): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (1): GroupNorm(8, 96, eps=1e-05, affine=True)\n          (2): ReLU(inplace=True)\n          (3): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (4): GroupNorm(8, 96, eps=1e-05, affine=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (enc3): Down(\n    (encoder): Sequential(\n      (0): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConv(\n        (double_conv): Sequential(\n          (0): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (1): GroupNorm(8, 192, eps=1e-05, affine=True)\n          (2): ReLU(inplace=True)\n          (3): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (4): GroupNorm(8, 192, eps=1e-05, affine=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (enc4): Down(\n    (encoder): Sequential(\n      (0): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConv(\n        (double_conv): Sequential(\n          (0): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (1): GroupNorm(8, 192, eps=1e-05, affine=True)\n          (2): ReLU(inplace=True)\n          (3): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (4): GroupNorm(8, 192, eps=1e-05, affine=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (dec1): Up(\n    (up): Upsample(scale_factor=(1.0, 2.0, 2.0), mode='trilinear')\n    (conv): DoubleConv(\n      (double_conv): Sequential(\n        (0): Conv3d(384, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n        (1): GroupNorm(8, 96, eps=1e-05, affine=True)\n        (2): ReLU(inplace=True)\n        (3): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n        (4): GroupNorm(8, 96, eps=1e-05, affine=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (dec2): Up(\n    (up): Upsample(scale_factor=(1.0, 2.0, 2.0), mode='trilinear')\n    (conv): DoubleConv(\n      (double_conv): Sequential(\n        (0): Conv3d(192, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n        (1): GroupNorm(8, 48, eps=1e-05, affine=True)\n        (2): ReLU(inplace=True)\n        (3): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n        (4): GroupNorm(8, 48, eps=1e-05, affine=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (dec3): Up(\n    (up): Upsample(scale_factor=(1.0, 2.0, 2.0), mode='trilinear')\n    (conv): DoubleConv(\n      (double_conv): Sequential(\n        (0): Conv3d(96, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n        (1): GroupNorm(8, 24, eps=1e-05, affine=True)\n        (2): ReLU(inplace=True)\n        (3): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n        (4): GroupNorm(8, 24, eps=1e-05, affine=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (dec4): Up(\n    (up): Upsample(scale_factor=(1.0, 2.0, 2.0), mode='trilinear')\n    (conv): DoubleConv(\n      (double_conv): Sequential(\n        (0): Conv3d(48, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n        (1): GroupNorm(8, 24, eps=1e-05, affine=True)\n        (2): ReLU(inplace=True)\n        (3): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n        (4): GroupNorm(8, 24, eps=1e-05, affine=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (out): Out(\n    (conv): Conv3d(24, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n  )\n)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())\n",
    "\n",
    "model_name = 'int_2'\n",
    "model = torch.load(os.path.join('models',model_name,f'{model_name}.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T09:37:38.454112356Z",
     "start_time": "2024-04-02T09:37:38.446486601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'model_name': 'int_2',\n 'depth / img_size / in_channel / n_channel': [78, 120, 3, 24],\n 'used_channel': ['-t1n.nii.gz', '-t1c.nii.gz', '-t2f.nii.gz'],\n 'val score(dice/jaccard)': [0.849, 0.754],\n 'batch/total epoch/best epoch': [4, 20, 16],\n 'resize_info': [0, 155, 2],\n 'run time(m)': 147}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('models/model_subscriptions.json','r') as f:\n",
    "    models_info = json.load(f)\n",
    "model_info = next((model for model in models_info if model['model_name'] == model_name), None)\n",
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from utils import get_dataloader\n",
    "from dataset import BratsDataset\n",
    "\n",
    "test_dataloader = get_dataloader(dataset=BratsDataset, phase=\"test\", resize_info=model_info['resize_info'], img_width=model_info['depth / img_size / in_channel / n_channel'][1], data_type=model_info['used_channel'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T09:37:39.354556606Z",
     "start_time": "2024-04-02T09:37:39.184575677Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T09:37:46.210735621Z",
     "start_time": "2024-04-02T09:37:40.459355995Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 824.00 MiB (GPU 0; 11.87 GiB total capacity; 1.39 GiB already allocated; 770.19 MiB free; 1.54 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 16\u001B[0m\n\u001B[1;32m     13\u001B[0m images \u001B[38;5;241m=\u001B[39m images\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     14\u001B[0m targets \u001B[38;5;241m=\u001B[39m targets\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m---> 16\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m probabilities \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msigmoid(logits)\n\u001B[1;32m     18\u001B[0m predictions \u001B[38;5;241m=\u001B[39m (probabilities \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.33\u001B[39m)\u001B[38;5;241m.\u001B[39mfloat()\n",
      "File \u001B[0;32m~/anaconda3/envs/hamin/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/unetBasic/model.py:112\u001B[0m, in \u001B[0;36mUNet3d.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    110\u001B[0m mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdec2(mask, x3)\n\u001B[1;32m    111\u001B[0m mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdec3(mask, x2)\n\u001B[0;32m--> 112\u001B[0m mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdec4\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    113\u001B[0m mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mout(mask)\n\u001B[1;32m    115\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;124;03mAfter a series of either Upsampling / 3d Transpose\u001B[39;00m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;124;03ma segmented image of the input image is generated \u001B[39;00m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;124;03m& returned \u001B[39;00m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/hamin/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/unetBasic/model.py:70\u001B[0m, in \u001B[0;36mUp.forward\u001B[0;34m(self, x1, x2)\u001B[0m\n\u001B[1;32m     66\u001B[0m diffX \u001B[38;5;241m=\u001B[39m x2\u001B[38;5;241m.\u001B[39msize()[\u001B[38;5;241m4\u001B[39m] \u001B[38;5;241m-\u001B[39m x1\u001B[38;5;241m.\u001B[39msize()[\u001B[38;5;241m4\u001B[39m]\n\u001B[1;32m     67\u001B[0m x1 \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mpad(x1, [diffX \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m, diffX \u001B[38;5;241m-\u001B[39m diffX \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m, diffY \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m\n\u001B[1;32m     68\u001B[0m            \u001B[38;5;241m2\u001B[39m, diffY \u001B[38;5;241m-\u001B[39m diffY \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m, diffZ \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m, diffZ \u001B[38;5;241m-\u001B[39m diffZ \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m])\n\u001B[0;32m---> 70\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx1\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv(x)\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 824.00 MiB (GPU 0; 11.87 GiB total capacity; 1.39 GiB already allocated; 770.19 MiB free; 1.54 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "total_predictions = []\n",
    "counter = 0  # Counter to keep track of the number of entries processed\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculations to save memory\n",
    "    for data in tqdm(test_dataloader):\n",
    "        \n",
    "        images, targets = data['image'], data['mask']\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits = model(images)\n",
    "        probabilities = torch.sigmoid(logits)\n",
    "        predictions = (probabilities >= 0.33).float()\n",
    "        total_predictions.append(predictions)\n",
    "        # Compute binary segmentation metrics\n",
    "        tp += torch.sum((predictions == 1) & (targets == 1)).item()\n",
    "        fp += torch.sum((predictions == 1) & (targets == 0)).item()\n",
    "        tn += torch.sum((predictions == 0) & (targets == 0)).item()\n",
    "        fn += torch.sum((predictions == 0) & (targets == 1)).item()\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        # Free memory by clearing intermediate variables\n",
    "        del images, targets, logits, probabilities, predictions\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T09:37:04.587491479Z",
     "start_time": "2024-04-02T09:37:04.586600791Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"True positives : {tp}\")\n",
    "print(f\"False positives : {fp}\")\n",
    "print(f\"True Negatives : {tn}\")\n",
    "print(f\"False Negatives : {fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T09:37:04.587845421Z",
     "start_time": "2024-04-02T09:37:04.587735442Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(tp, fp, tn, fn):\n",
    "    # Create confusion matrix array\n",
    "    confusion_matrix = np.array([[tn, fp], [fn, tp]])\n",
    "\n",
    "    # Set up labels for matrix\n",
    "    labels = ['True ', 'False ']\n",
    "\n",
    "    # Create color map\n",
    "    cmap = plt.cm.Blues\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.imshow(confusion_matrix, interpolation='nearest', cmap=cmap)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Add labels to matrix cells\n",
    "    thresh = confusion_matrix.max() / 2.\n",
    "    for i, j in np.ndindex(confusion_matrix.shape):\n",
    "        plt.text(j, i, format(confusion_matrix[i, j], 'd'), horizontalalignment='center', color='white' if confusion_matrix[i, j] > thresh else 'black')\n",
    "\n",
    "    # Set tick labels\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "\n",
    "    # Set axis labels\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(tp, fp, tn, fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T09:37:04.589214226Z",
     "start_time": "2024-04-02T09:37:04.589103002Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:37:04.590461966Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Accuracy : {accuracy*100}\")\n",
    "print(f\"Precision : {precision*100}\")\n",
    "print(f\"Recall : {recall*100}\")\n",
    "print(f\"F1 Score : {f1_score*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:37:04.591783791Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc \n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tqdm import tqdm\n",
    "gc.collect()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "predictions = []\n",
    "total_targets = []\n",
    "# Counter to keep track of the number of entries processed\n",
    "counter = 0  \n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_dataloader):\n",
    "        if counter >= 5:\n",
    "            break  # Stop processing entries if the desired number is reached\n",
    "\n",
    "        images, targets = data['image'], data['mask']\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits = model(images)\n",
    "        probabilities = torch.sigmoid(logits)\n",
    "        prediction = (probabilities >= 0.33).float()\n",
    "\n",
    "        prediction =  prediction.cpu()\n",
    "        targets = targets.cpu()\n",
    "        total_targets.append(targets)\n",
    "        predictions.append(prediction)\n",
    "\n",
    "        model.zero_grad()\n",
    "        del images, targets, logits, probabilities, prediction\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:37:04.593081325Z"
    }
   },
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:37:04.594044987Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "y_true = np.concatenate(total_targets)\n",
    "y_pred = np.concatenate(predictions)\n",
    "\n",
    "y_true.shape, y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:37:04.594819903Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import dice_coef_metric_per_classes, jaccard_coef_metric_per_classes\n",
    "def compute_scores_per_classes(model,          # nodel which is UNeT3D \n",
    "                               dataloader,     # tuple consisting of ( id , image tensor , mask tensor )\n",
    "                               classes):       # classes : WT , TC , ET \n",
    "    \"\"\"\n",
    "    Compute Dice and Jaccard coefficients for each class.\n",
    "    Params:\n",
    "        model: neural net for make predictions.\n",
    "        dataloader: dataset object to load data from.\n",
    "        classes: list with classes.\n",
    "        Returns: dictionaries with dice and jaccard coefficients for each class for each slice.\n",
    "    \"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    dice_scores_per_classes = {key: list() for key in classes}\n",
    "    iou_scores_per_classes = {key: list() for key in classes}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader):\n",
    "            imgs, targets = data['image'], data['mask']\n",
    "            imgs, targets = imgs.to(device), targets.to(device)\n",
    "            logits = model(imgs)\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            targets = targets.detach().cpu().numpy()\n",
    "            \n",
    "            # Now finding the overlap between the raw prediction i.e. logit & the mask i.e. target & finding the dice & iou scores \n",
    "            dice_scores = dice_coef_metric_per_classes(logits, targets)\n",
    "            iou_scores = jaccard_coef_metric_per_classes(logits, targets)\n",
    "\n",
    "            # storing both dice & iou scores in the list declared \n",
    "            for key in dice_scores.keys():\n",
    "                dice_scores_per_classes[key].extend(dice_scores[key])\n",
    "\n",
    "            for key in iou_scores.keys():\n",
    "                iou_scores_per_classes[key].extend(iou_scores[key])\n",
    "\n",
    "    return dice_scores_per_classes, iou_scores_per_classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:37:04.616776678Z"
    }
   },
   "outputs": [],
   "source": [
    "dice_scores_per_classes, iou_scores_per_classes = compute_scores_per_classes(\n",
    "    model, test_dataloader, ['WT', 'TC', 'ET']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:37:04.616955442Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dice_df = pd.DataFrame(dice_scores_per_classes)\n",
    "dice_df.columns = ['WT dice', 'TC dice', 'ET dice']\n",
    "\n",
    "iou_df = pd.DataFrame(iou_scores_per_classes)\n",
    "iou_df.columns = ['WT jaccard', 'TC jaccard', 'ET jaccard']\n",
    "# CONCAT BOTH THE COLUMNS ALONG AXIS 1 & SORT THE TWO \n",
    "val_metics_df = pd.concat([dice_df, iou_df], axis=1, sort=True)\n",
    "val_metics_df = val_metics_df.loc[:, ['WT dice', 'WT jaccard', \n",
    "                                      'TC dice', 'TC jaccard', \n",
    "                                      'ET dice', 'ET jaccard']]\n",
    "val_metics_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:37:04.617042285Z"
    }
   },
   "outputs": [],
   "source": [
    "[i for i in val_metics_df.std()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:37:04.617115862Z"
    }
   },
   "outputs": [],
   "source": [
    "val_metics_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:37:04.617189181Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "colors = ['#264653', '#2a9d8f', '#8ab17d', '#e9c46a', '#f4a261', '#e76f51']\n",
    "palette = sns.color_palette(colors, 6)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.barplot(x=val_metics_df.mean().index, y=val_metics_df.mean(), palette=palette, ax=ax)\n",
    "ax.set_xticklabels(val_metics_df.columns, fontsize=14, rotation=15)\n",
    "ax.set_title(\"Dice and Jaccard Coefficients from Test\", fontsize=20)\n",
    "\n",
    "for idx, p in enumerate(ax.patches):\n",
    "        percentage = '{:.1f}%'.format(100 * val_metics_df.mean().values[idx])\n",
    "        x = p.get_x() + p.get_width() / 2 - 0.15\n",
    "        y = p.get_y() + p.get_height()\n",
    "        ax.annotate(percentage, (x, y), fontsize=15, fontweight=\"bold\")\n",
    "\n",
    "fig.savefig(\"result1.png\", format=\"png\",  pad_inches=0.2, transparent=False, bbox_inches='tight')\n",
    "fig.savefig(\"result1.svg\", format=\"svg\",  pad_inches=0.2, transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:37:04.617260310Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hamin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
