{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model, test batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet3d(\n",
       "  (conv): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv3d(3, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (enc1): Down(\n",
       "    (encoder): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (4): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (enc2): Down(\n",
       "    (encoder): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (4): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (enc3): Down(\n",
       "    (encoder): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (4): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (enc4): Down(\n",
       "    (encoder): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (4): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec1): Up(\n",
       "    (up): Upsample(scale_factor=(1.0, 2.0, 2.0), mode='trilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv3d(512, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (4): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec2): Up(\n",
       "    (up): Upsample(scale_factor=(1.0, 2.0, 2.0), mode='trilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv3d(256, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (4): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec3): Up(\n",
       "    (up): Upsample(scale_factor=(1.0, 2.0, 2.0), mode='trilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec4): Up(\n",
       "    (up): Upsample(scale_factor=(1.0, 2.0, 2.0), mode='trilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Out(\n",
       "    (conv): Conv3d(32, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from model import UNet3d\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet3d(in_channels=3, n_classes=3, n_channels=32)\n",
    "model.load_state_dict(torch.load('saved_model/best-basic-e100.pth'))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import get_dataloader\n",
    "from dataset import BratsDataset\n",
    "\n",
    "val_dataloader = get_dataloader(dataset=BratsDataset, phase=\"val\")\n",
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Id', 'image', 'mask'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BraTS-GLI-01344-000', 'BraTS-GLI-00703-001', 'BraTS-GLI-00097-000', 'BraTS-GLI-01147-000']\n",
      "torch.Size([4, 3, 78, 120, 120])\n",
      "torch.Size([4, 3, 78, 120, 120])\n"
     ]
    }
   ],
   "source": [
    "batch_id, images, targets = test_batch['Id'], test_batch['image'], test_batch['mask']\n",
    "print(batch_id)\n",
    "print(images.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.to(device)\n",
    "targets = targets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 78, 120, 120)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = targets.detach().cpu().numpy()\n",
    "targets = targets[0]\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load original 155 slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155, 240, 240)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "data_path = 'brats_data'\n",
    "phase = 'val'\n",
    "id_ = batch_id[0]\n",
    "data_type = '-seg.nii.gz'\n",
    "_whole_slices = nib.load(os.path.join(data_path, phase, id_, id_+data_type))\n",
    "_whole_slices = np.asarray(_whole_slices.dataobj) #(240,240,155)\n",
    "_whole_slices = _whole_slices.transpose(2,0,1)\n",
    "_whole_slices.shape # (155,240,240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mask_labels(mask):\n",
    "    print(\"before preprocess\", mask.shape)\n",
    "    # whole tumour\n",
    "    mask_WT = mask.copy()\n",
    "    mask_WT[mask_WT == 1] = 1\n",
    "    mask_WT[mask_WT == 2] = 1\n",
    "    mask_WT[mask_WT == 3] = 1\n",
    "    # include all tumours \n",
    "\n",
    "    # NCR / NET - LABEL 1\n",
    "    mask_TC = mask.copy()\n",
    "    mask_TC[mask_TC == 1] = 1\n",
    "    mask_TC[mask_TC == 2] = 0\n",
    "    mask_TC[mask_TC == 3] = 1\n",
    "    # exclude 2 / 4 labelled tumour \n",
    "\n",
    "    # ET - LABEL 4 \n",
    "    mask_ET = mask.copy()\n",
    "    mask_ET[mask_ET == 1] = 0\n",
    "    mask_ET[mask_ET == 2] = 0\n",
    "    mask_ET[mask_ET == 3] = 1\n",
    "    # exclude 2 / 1 labelled tumour \n",
    "\n",
    "    # mask = np.stack([mask_WT, mask_TC, mask_ET, mask_ED])\n",
    "    mask = np.stack([mask_WT, mask_TC, mask_ET])\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before preprocess (155, 240, 240)\n",
      "after preprocess (3, 155, 240, 240)\n"
     ]
    }
   ],
   "source": [
    "whole_slices = preprocess_mask_labels(_whole_slices)\n",
    "print(\"after preprocess\", whole_slices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model and preprocess output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 78, 120, 120])\n",
      "torch.Size([1, 64, 78, 60, 60])\n",
      "torch.Size([1, 128, 78, 30, 30])\n",
      "torch.Size([1, 256, 78, 15, 15])\n",
      "torch.Size([1, 256, 78, 7, 7])\n",
      "0 1 (1, 3, 78, 120, 120)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(images[0].unsqueeze(0))\n",
    "    pred = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "    threshold = 0.33\n",
    "    pred = (pred >= threshold).astype(int)\n",
    "    print(pred.min(), pred.max(), pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "pred = pred[0] #(3,78,120,120)\n",
    "resized_pred = resize(pred,(3,155,240,240), preserve_range=True) #(3,155,240,240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 78, 120, 120), (3, 155, 240, 240))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape, resized_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_set = {\n",
    "    \"WT\": targets[0],\n",
    "    \"TC\": targets[1],\n",
    "    \"ET\": targets[2],\n",
    "}\n",
    "pred_set = {\n",
    "    \"WT\": pred[0],\n",
    "    \"TC\": pred[1],\n",
    "    \"ET\": pred[2],\n",
    "}\n",
    "ori_mask_set = {\n",
    "    \"WT\": whole_slices[0],\n",
    "    \"TC\": whole_slices[1],\n",
    "    \"ET\": whole_slices[2],\n",
    "}\n",
    "ori_pred_set = {\n",
    "    \"WT\": resized_pred[0],\n",
    "    \"TC\": resized_pred[1],\n",
    "    \"ET\": resized_pred[2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def comp_gt_pred(percent, slices, gt, pred):\n",
    "    slide2show = int(percent/100*slices)\n",
    "    print(slide2show)\n",
    "    plt.suptitle(f\"Compare at slice {slide2show}/{slices}({percent}%)\")\n",
    "    for i,clas in enumerate(gt):\n",
    "        plt.subplot(2,3,i+1)\n",
    "        plt.title(f'GT of {clas}')\n",
    "        plt.imshow(gt[clas][slide2show], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(2,3,i+1+3)\n",
    "        plt.title(f'prediction of {clas}')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(pred[clas][slide2show], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for percent in range(30,50,4):\n",
    "#     comp_gt_pred(percent,78, mask_set, pred_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for percent in range(30,50,4):\n",
    "#     comp_gt_pred(percent,155, ori_mask_set, ori_pred_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('slice_to_78.txt','a') as f:\n",
    "    for cut_idx, real_idx in enumerate(np.arange(0, 155, 2)):\n",
    "        f.write(f\"{cut_idx}, {real_idx}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('slice_to_50.txt','a') as f:\n",
    "    for cut_idx, real_idx in enumerate(np.arange(3, 153, 3)):\n",
    "        f.write(f\"{cut_idx}, {real_idx}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 155, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_num, end_num, interval = [0,155,2]\n",
    "start_num, end_num, interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dt = [int(_) for _ in input(\"Enter resizing start, end, interval: \").split(',')]\n",
    "data = [[cut_idx, real_idx] for cut_idx, real_idx in enumerate(range(*dt))]\n",
    "with open('data.json','w') as f:\n",
    "    json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hamin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
