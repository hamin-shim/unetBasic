{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 2\n",
      "{'model_name': 'ch3_32_interval_3_240', 'depth / in_channel / n_channel': [52, 3, 32], 'img_size': 240, 'used_channel': ['-t1n.nii.gz', '-t1c.nii.gz', '-t2f.nii.gz'], 'val score(dice/jaccard)': [88, 81], 'batch/total epoch/best epoch': [1, 50, 33], 'resize_info': [0, 155, 3], 'run time(m)': 1360.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Set:  16%|█▌        | 5/32 [00:44<03:58,  8.84s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from utils import get_dataloader, load_test_dataset\n",
    "from dataset import BratsDataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from eval_utils import compute_dice\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"  # Set the GPUs 2 and 3 to use\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())\n",
    "\n",
    "with open('models/model_subscriptions.json', 'r') as f:\n",
    "    models_info = json.load(f)\n",
    "model_name = 'ch3_32_interval_3_240'\n",
    "model_info = next(\n",
    "    (model for model in models_info if model['model_name'] == model_name), None)\n",
    "print(model_info)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "_model = torch.load(os.path.join('models', model_name, f\"{model_name}.pth\"))\n",
    "_model = _model.to(device)\n",
    "model = nn.DataParallel(_model).to(device)\n",
    "model.eval()\n",
    "\n",
    "test_dataloader = get_dataloader(dataset=BratsDataset, phase=\"test\",\n",
    "                                 resize_info=model_info['resize_info'], img_width=model_info['img_size'], data_type=model_info['used_channel'], batch_size=4)\n",
    "# Check dataloader\n",
    "# test_batch = next(iter(test_dataloader))\n",
    "# batch_id, images, targets = test_batch['Id'], test_batch['image'], test_batch['mask']\n",
    "# images = images.to(device)\n",
    "# targets = targets.to(device)\n",
    "# print('batch id', batch_id)\n",
    "# print('loaded image, target shape', images.shape, targets.shape)\n",
    "\n",
    "predictions_arr = []\n",
    "batch_ids= []\n",
    "cnt = 0\n",
    "with torch.no_grad():\n",
    "    for itr, data_batch in tqdm(enumerate(test_dataloader), total=len(test_dataloader), desc=f'Test Set'):\n",
    "        if cnt == 5:\n",
    "            break\n",
    "        batch_id, images, targets = data_batch['Id'], data_batch['image'], data_batch['mask']\n",
    "        batch_ids.append(batch_id)\n",
    "        images = images.to(device)\n",
    "        logits = model(images)\n",
    "        pred = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "        threshold = 0.33\n",
    "        pred = (pred >= threshold).astype(int)\n",
    "        pred = np.array([resize(_pred, (3, 155, 240, 240), preserve_range=True)\n",
    "                         for _pred in pred])\n",
    "        predictions_arr.append(pred)\n",
    "        del images, targets, logits, pred\n",
    "        torch.cuda.empty_cache()\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, (4, 3, 155, 240, 240))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "len(predictions_arr), predictions_arr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 3, 155, 240, 240)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for batch_id in batch_ids:\n",
    "    d.append(load_test_dataset(batch_id))\n",
    "targets = np.stack(d)\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8764808824034401\n"
     ]
    }
   ],
   "source": [
    "if(targets.shape==predictions.shape):\n",
    "    print(compute_dice(targets, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hamin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
